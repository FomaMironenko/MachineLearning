{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foma Mironenko, <br>SPbU, Faculty of Mathematics and Mechanics,<br>431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN, *Part I*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The purpose of this work is to automatically recognize hand-written digits with a high level of confidence. As a source images set we use @MNIST dataset. The resulting model precision is measured on a testing images sample. Finally we apply the model to custom images set and compare predicted values against the real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose a convolutional neural network (CNN) as a classifier. The network structure is as follows:\n",
    "- *Convolution* 3x3, 32 filt\n",
    "- *Max Pooling* 2x2\n",
    "- *Batch Normalization*\n",
    "- *Convolution* 3x3, 16 filt\n",
    "- *Flattening*\n",
    "- *Dense* 160, relu\n",
    "- *Dense* 10, softmax\n",
    "\n",
    "### The total number of optimization parameters is 316\\`602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We split the total sample of 60k images into a training and testing sets in proportion 5 : 1 respectively, which are 50k and 10k. <br>Achieved precision at the testing set is 98.89%.<br>However the custom images performance leaves much to be desired. Digits 6, 8, 9 are purely recognizable by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- data handling -----#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- conv net -----#\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(array, R, C):\n",
    "    array = array.reshape((R, C));\n",
    "    img = Image.fromarray(255 - array, 'P');\n",
    "    img.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(S: bytes):\n",
    "    return int.from_bytes(S, byteorder='big');\n",
    "\n",
    "def parse_images(k: int):\n",
    "    #----- read a file -----#\n",
    "    f = open(\"./train-images-idx3-ubyte\", \"rb\");\n",
    "    assert(decode(f.read(4)) == 2051);\n",
    "    N = decode(f.read(4));\n",
    "    assert(k <= N);\n",
    "    #----- parse image data -----#\n",
    "    R = decode(f.read(4));\n",
    "    C = decode(f.read(4));\n",
    "    assert(R == 28 and C == 28);\n",
    "    images = [];\n",
    "    for j in range(k):\n",
    "        bits = [decode(f.read(1)) for i in range(R*C)];\n",
    "        img = np.array(bits, dtype=np.uint8)\n",
    "        images.append(img);\n",
    "    f.close();\n",
    "    return images, R, C;\n",
    "\n",
    "def parse_labels(k: int):\n",
    "    #----- read a file -----#\n",
    "    f = open(\"./train-labels-idx1-ubyte\", \"rb\");\n",
    "    assert(decode(f.read(4)) == 2049);\n",
    "    N = decode(f.read(4));\n",
    "    assert(k <= N);\n",
    "    #----- parse label data -----#\n",
    "    result = [decode(f.read(1)) for i in range(k)]\n",
    "    f.close();\n",
    "    return result;\n",
    "\n",
    "def parse_data(k: int):\n",
    "    #----- create a dataset -----#\n",
    "    imgs, R, C = parse_images(k);\n",
    "    labs = parse_labels(k);\n",
    "    return pd.DataFrame({'image': imgs, 'label': labs}), R, C;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = 50000;\n",
    "Ntest  = 10000;\n",
    "N = Ntrain + Ntest;\n",
    "df, R, C = parse_data(N);\n",
    "\n",
    "df_test  = df.iloc[range(Ntest), :];\n",
    "df_train = df.iloc[range(Ntest, N), :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training set\n",
    "#### The model return is a vector of lenght 10. So we need to convert labels to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.stack( df_train\n",
    "    .loc[:, 'image']\n",
    "    .apply(lambda arr: arr.reshape((R, C))\n",
    "));\n",
    "\n",
    "inds = list(df_train.loc[:, 'label']);\n",
    "Ytrain = np.zeros((Ntrain, 10));\n",
    "Ytrain[range(Ntrain), inds] = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a conv net with max pooling and dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(\n",
    "        shape=(R, C, 1)),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=32, \n",
    "        kernel_size=(3, 3), \n",
    "        activation='relu'),\n",
    "    keras.layers.MaxPool2D(\n",
    "        pool_size=(2, 2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=16, \n",
    "        kernel_size=(3, 3), \n",
    "        activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        160, activation='relu'),\n",
    "    keras.layers.Dense(\n",
    "        10, activation='softmax')\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='kl_divergence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 13, 13, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 11, 11, 16)        4624      \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 160)               309920    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1610      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316,602\n",
      "Trainable params: 316,538\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 10s 191ms/step - loss: 0.5401\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 10s 199ms/step - loss: 0.1232\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 10s 208ms/step - loss: 0.0636\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 10s 204ms/step - loss: 0.0399\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 10s 204ms/step - loss: 0.0287\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 10s 199ms/step - loss: 0.0185\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 10s 201ms/step - loss: 0.0166\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 10s 203ms/step - loss: 0.0125\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.0107\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 0.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5e0d4fca0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, batch_size=1000, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.0206\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.0012\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3a0eaba60>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, batch_size=10000, epochs=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict testing labels and compare with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "Model precision: 98.89%\n"
     ]
    }
   ],
   "source": [
    "Xtest = np.stack(df_test\n",
    "        .loc[:, 'image']\n",
    "        .apply(lambda arr: arr.reshape((R, C))\n",
    "));\n",
    "\n",
    "Ytest = np.argmax( \n",
    "    model.predict(Xtest, verbose=True), \n",
    "    axis=1 \n",
    ");\n",
    "\n",
    "Yactual = df_test.loc[:, 'label'];\n",
    "\n",
    "precision_pct = 100 * np.equal(Ytest, Yactual).sum() / Ntest;\n",
    "print(f\"Model precision: {precision_pct}%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model if intended precision was reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained-model/assets\n"
     ]
    }
   ],
   "source": [
    "if precision_pct >= 98.0:\n",
    "    model.save('./trained-model', overwrite=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
